# å¤šæ¨¡æ€å¯¹è¯ç¤ºä¾‹
ç®€ä½“ä¸­æ–‡ | [English](./README_EN.md)


### :point_right: å‰ç½®æ¡ä»¶

1. #### é…ç½®é˜¿é‡Œäº‘ç™¾ç‚¼ API-KEY

    åœ¨è¿è¡Œæ­¤ç¤ºä¾‹ä¹‹å‰ï¼Œæ‚¨éœ€è¦æ¿€æ´»é˜¿é‡Œäº‘è´¦æˆ·ï¼Œè·å–é˜¿é‡Œäº‘ç™¾ç‚¼ API_KEYï¼Œå¹¶è¿›è¡Œå¿…è¦çš„ç¯å¢ƒé…ç½®ã€‚æœ‰å…³ API-KEY çš„è¯¦ç»†é…ç½®æ­¥éª¤ï¼Œè¯·å‚è€ƒï¼š[PREREQUISITES.md](../../../../PREREQUISITES.md)

2. #### å¼€å¯å¤šæ¨¡æ€å¯¹è¯æœåŠ¡
    åœ¨è¿è¡Œæ­¤ç¤ºä¾‹ä¹‹å‰ï¼Œæ‚¨éœ€è¦åœ¨å¤šæ¨¡äº¤äº’æœåŠ¡ç®¡æ§å°å¼€é€šå¤šæ¨¡æ€å¯¹è¯æœåŠ¡ã€‚å¹¶åœ¨æ§åˆ¶å°ä¸­åˆ›å»ºåº”ç”¨å¹¶è¿›è¡Œå¿…è¦é…ç½®ï¼Œå‘å¸ƒåº”ç”¨ã€‚åŒæ—¶è·å– app_idã€workspace_id å’Œ api_keyã€‚

3. #### å®‰è£… Python ä¾èµ–

    é˜¿é‡Œäº‘ç™¾ç‚¼ SDK è¿è¡Œç¯å¢ƒéœ€è¦ Python 3.9 æˆ–æ›´é«˜ç‰ˆæœ¬ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…æ­¤ç¤ºä¾‹çš„ä¾èµ–é¡¹ï¼š
    ```commandline
    pip3 install -r requirements.txt
    ```

### :point_right: è¿è¡Œç¤ºä¾‹
è¯·ä¿®æ”¹ç¤ºä¾‹ä»¥å¡«å…¥å¿…è¦çš„ app_idã€workspace_id å’Œ api_keyã€‚æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿è¡Œæ­¤ç¤ºä¾‹ï¼š

```commandline
export DASHSCOPE_LOGGING_LEVEL='info' # å¯ç”¨ dashscope SDK å†…éƒ¨æ—¥å¿—
python3 run.py
```
ç¤ºä¾‹é»˜è®¤ä½¿ç”¨ Push2talk æ¨¡å¼è°ƒç”¨æœåŠ¡ï¼Œè¯»å–è¯­éŸ³æ–‡ä»¶"1åŠ 1ç­‰äºå¤šå°‘"çš„éŸ³é¢‘è¯†åˆ«å¹¶å›å¤æ–‡æœ¬å’ŒéŸ³é¢‘å›å¤ã€‚

### å¿«é€Ÿé›†æˆ

#### 1. å®‰è£…ä¾èµ–

```bash
pip install dashscope
```

#### 2. åŸºç¡€é…ç½®

```python
from dashscope.multimodal.dialog_state import DialogState
from dashscope.multimodal.multimodal_dialog import MultiModalDialog, MultiModalCallback
from dashscope.multimodal.multimodal_request_params import (
    Upstream, Downstream, ClientInfo, RequestParameters, Device
)

# é…ç½®å‚æ•°
WORKSPACE_ID = "your_workspace_id"
APP_ID = "your_app_id"
API_KEY = "your_api_key"
MODEL = "multimodal-dialog"
WEBSOCKET_URL = "wss://dashscope.aliyuncs.com/api-ws/v1/inference"
```

#### 3. å®ç°å›è°ƒå¤„ç†å™¨

```python
class ChatCallback(MultiModalCallback):
    """å¯¹è¯å›è°ƒå¤„ç†å™¨"""
    
    def on_connected(self):
        print("âœ… WebSocket è¿æ¥å·²å»ºç«‹")

    def on_started(self, dialog_id: str):
        print(f"å¯¹è¯å·²å¼€å§‹ï¼ŒID: {dialog_id}")

    def on_state_changed(self, state: DialogState):
        state_messages = {
            DialogState.LISTENING: "ğŸ‘‚ ç³»ç»Ÿæ­£åœ¨ç›‘å¬...",
            DialogState.THINKING: "ğŸ¤” AI æ­£åœ¨æ€è€ƒ...",
            DialogState.RESPONDING: "ğŸ’¬ AI æ­£åœ¨å›åº”..."
        }
        print(state_messages.get(state, f"çŠ¶æ€å˜æ›´: {state}"))

    def on_speech_audio_data(self, data: bytes):
        print(f"æ¥æ”¶åˆ°éŸ³é¢‘æ•°æ®: {len(data)} å­—èŠ‚")

    def on_error(self, error: Exception):
        print(f"âŒ é”™è¯¯: {error}")

    def on_close(self, close_status_code: int, close_msg: str):
        print(f"è¿æ¥å·²å…³é—­ - çŠ¶æ€: {close_status_code}, æ¶ˆæ¯: {close_msg}")
```

#### 4. å¯¹è¯ç®¡ç†å™¨

```python
class MultiModalConversation:
    """å¤šæ¨¡æ€å¯¹è¯ç®¡ç†å™¨"""
    
    def __init__(self, app_id: str, workspace_id: str, api_key: str, 
                 conversation_mode: str = "push2talk"):
        # é…ç½®ä¸Šè¡Œå‚æ•°
        up_stream = Upstream(
            type="AudioOnly", 
            mode=conversation_mode, 
            audio_format="pcm"
        )
        
        # é…ç½®å®¢æˆ·ç«¯ä¿¡æ¯
        client_info = ClientInfo(
            user_id="demo_user", 
            device=Device(uuid="demo_device")
        )
        
        # é…ç½®è¯·æ±‚å‚æ•°
        request_params = RequestParameters(
            upstream=up_stream,
            downstream=Downstream(voice="longxiaochun_v2", sample_rate=48000),
            client_info=client_info
        )

        # åˆå§‹åŒ–å¯¹è¯å®ä¾‹
        self.conversation = MultiModalDialog(
            app_id=app_id,
            workspace_id=workspace_id,
            url=WEBSOCKET_URL,
            request_params=request_params,
            multimodal_callback=ChatCallback(),
            api_key=api_key,
            model=MODEL
        )

    def start_conversation(self):
        """å¼€å§‹å¯¹è¯"""
        self.conversation.start("")
        print("ğŸ¯ å¯¹è¯å·²å¼€å§‹")

    def send_audio_file(self, file_path: str):
        """å‘é€éŸ³é¢‘æ–‡ä»¶"""
        # ç­‰å¾…ç›‘å¬çŠ¶æ€
        while self.conversation.get_dialog_state() != DialogState.LISTENING:
            time.sleep(0.1)
        
        # å¼€å§‹è¯­éŸ³è¯†åˆ«
        self.conversation.start_speech()
        
        # æµå¼å‘é€éŸ³é¢‘æ•°æ®
        with open(file_path, "rb") as f:
            while True:
                data = f.read(3200)
                if not data:
                    break
                self.conversation.send_audio_data(data)
                time.sleep(0.1)
        
        # åœæ­¢è¯­éŸ³è¯†åˆ«ï¼ˆPush2Talk æ¨¡å¼ï¼‰
        if self.conversation.get_conversation_mode() == "push2talk":
            self.conversation.stop_speech()

    def stop_conversation(self):
        """åœæ­¢å¯¹è¯"""
        self.conversation.stop()
        print("ğŸ›‘ å¯¹è¯å·²åœæ­¢")
```

#### 5. å®Œæ•´ç¤ºä¾‹

```python
import time

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨å¤šæ¨¡æ€å¯¹è¯æ¼”ç¤º")
    
    # é…ç½®å‚æ•°
    config = {
        'app_id': "your_app_id",
        'workspace_id': "your_workspace_id",
        'api_key': "your_api_key",
        'conversation_mode': "push2talk"
    }
    
    # éªŒè¯é…ç½®
    if not all([config['app_id'], config['workspace_id'], config['api_key']]):
        print("âŒ è¯·é…ç½® app_idã€workspace_id å’Œ api_key")
        return
    
    try:
        # åˆ›å»ºå¯¹è¯å®ä¾‹
        conversation = MultiModalConversation(**config)
        
        # å¼€å§‹å¯¹è¯
        conversation.start_conversation()
        
        # å‘é€éŸ³é¢‘æ–‡ä»¶
        conversation.send_audio_file("path/to/audio.wav")
        
        # ç­‰å¾…å¤„ç†å®Œæˆ
        time.sleep(10)
        
        # åœæ­¢å¯¹è¯
        conversation.stop_conversation()
        
        print("âœ… æ¼”ç¤ºå®Œæˆ")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")

if __name__ == '__main__':
    main()
```

### äº¤äº’æ¨¡å¼

#### 1. Push2Talk æ¨¡å¼
- **ç‰¹ç‚¹**: æŒ‰ä¸‹è¯´è¯ï¼Œæ¾å¼€åœæ­¢
- **é€‚ç”¨åœºæ™¯**: APPæˆ–è€…ç©å…·é€šè¿‡æŒ‰é’®è¯´è¯
- **å®ç°æ–¹å¼**: æ‰‹åŠ¨è°ƒç”¨ `start_speech()` å’Œ `stop_speech()`


#### 2. Tap2Talk æ¨¡å¼
- **ç‰¹ç‚¹**: ç‚¹å‡»å¼€å§‹ï¼Œè‡ªåŠ¨ç»“æŸæ£€æµ‹
- **é€‚ç”¨åœºæ™¯**: æ”¯æŒå”¤é†’çš„åœºæ™¯ï¼Œæˆ–è€…æŒ‰é”®å¼€å§‹
- **å®ç°æ–¹å¼**: åªè°ƒç”¨ `start_speech()`ï¼Œç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹ç»“æŸ

#### 3. Duplex æ¨¡å¼
- **ç‰¹ç‚¹**: å…¨åŒå·¥é€šä¿¡ï¼Œæ”¯æŒæ‰“æ–­
- **é€‚ç”¨åœºæ™¯**: å®æ—¶å¯¹è¯äº¤äº’
- **å®ç°æ–¹å¼**: ç›´æ¥å‘é€éŸ³é¢‘æ•°æ®ï¼Œæ— éœ€æ‰‹åŠ¨æ§åˆ¶

### åŠŸèƒ½ç‰¹æ€§

#### å›¾ç‰‡é—®ç­”ï¼ˆVQAï¼‰åŠŸèƒ½
```python
from dashscope.multimodal.multimodal_request_params import RequestToRespondParameters

def test_image_vqa_url(conversation, image_url: str, question: str):
    """ä½¿ç”¨ URL å›¾ç‰‡è¿›è¡Œ VQA"""
    # æ„å»ºå›¾ç‰‡å‚æ•°
    image = {"type": "url", "value": image_url}
    images_params = RequestToRespondParameters(images=[image])
    
    # å‘é€ VQA è¯·æ±‚
    conversation.request_to_respond("prompt", question, parameters=images_params)
```

#### æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰åŠŸèƒ½

```python
# å‘é€æ–‡æœ¬åˆæˆè¯·æ±‚
conversation.request_to_respond("transcript", "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬ã€‚", None)
```

### :point_right: æŠ€æœ¯æ”¯æŒ
<img src="https://dashscope.oss-cn-beijing.aliyuncs.com/samples/audio/group.png" width="400"/>